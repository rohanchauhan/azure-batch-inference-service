{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lead Scoring Batch Inference Pipeline\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we [UCI Bank Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing) dataset for lead scoring. Lead classification is used to score leads based on the information we gather. It is different from lead \n",
        "qualification which is used to identify ideal customers. Lead scoring helps sales and marketing team focus their efforts on customers who are most likely to buy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Workspace\n",
        "We use mlfow for tracking the experiment and logging metrics and artifacts "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from azureml.core import Workspace, Experiment\r\n",
        "import mlflow\r\n",
        "\r\n",
        "# Setup Azure Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "experiment_name = 'leads-pyspark-train'\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
        "\r\n",
        "# Start MLflow Experiment\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "run = mlflow.start_run()\r\n",
        "\r\n",
        "# Get Spark session\r\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006498190
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and Upload Batch Data\n",
        "We use most of the data for training and testing the model. Rest of the data is used\n",
        "to create batches by creating csv files with 10 records each. The batches are stored \n",
        "in local storage in folder called `batch-data`.\n",
        "\n",
        "After storing the batches in `batch-data`, the folder is uploaded to blob storage \n",
        "using datastore. The dataset is registered as File Dataset. Later on, we can monitor\n",
        "data drift by creating base and target dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "df = spark.read.csv(\r\n",
        "    path='data/bank-additional-full.csv',\r\n",
        "    header=\"true\",\r\n",
        "    inferSchema=\"true\",\r\n",
        "    sep=\";\")\r\n",
        "trainDF, testDF, batchDF = df.randomSplit([.7, .29, .01], seed=999)\r\n",
        "batchData = batchDF.toPandas()\r\n",
        "\r\n",
        "# Create a folder for storing generated batch data\r\n",
        "batch_folder = './batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "# Save each sample as a separate file\r\n",
        "print(\"Saving files...\")\r\n",
        "x = 0\r\n",
        "y = 10\r\n",
        "for i in range(int(batchDF.count()/10)):\r\n",
        "    filename = str(i+1) + '.csv'\r\n",
        "    writeData=batchData[x:y]\r\n",
        "    writeData.to_csv(os.path.join(batch_folder, filename), sep=\",\")\r\n",
        "    x+=10\r\n",
        "    y+=10\r\n",
        "\r\n",
        "print(\"files saved!\")\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \r\n",
        "                                             name='leads-batch-data',\r\n",
        "                                             description='batch data for Marketing Leads UCI',\r\n",
        "                                             create_new_version=True)\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created!\n",
            "Saving files...\n",
            "files saved!\n",
            "Uploading files to datastore...\n",
            "Uploading an estimated of 40 files\n",
            "Uploading batch-data/1.csv\n",
            "Uploaded batch-data/1.csv, 1 files out of an estimated total of 40\n",
            "Uploading batch-data/10.csv\n",
            "Uploaded batch-data/10.csv, 2 files out of an estimated total of 40\n",
            "Uploading batch-data/11.csv\n",
            "Uploaded batch-data/11.csv, 3 files out of an estimated total of 40\n",
            "Uploading batch-data/12.csv\n",
            "Uploaded batch-data/12.csv, 4 files out of an estimated total of 40\n",
            "Uploading batch-data/13.csv\n",
            "Uploaded batch-data/13.csv, 5 files out of an estimated total of 40\n",
            "Uploading batch-data/14.csv\n",
            "Uploaded batch-data/14.csv, 6 files out of an estimated total of 40\n",
            "Uploading batch-data/15.csv\n",
            "Uploaded batch-data/15.csv, 7 files out of an estimated total of 40\n",
            "Uploading batch-data/16.csv\n",
            "Uploaded batch-data/16.csv, 8 files out of an estimated total of 40\n",
            "Uploading batch-data/17.csv\n",
            "Uploaded batch-data/17.csv, 9 files out of an estimated total of 40\n",
            "Uploading batch-data/18.csv\n",
            "Uploaded batch-data/18.csv, 10 files out of an estimated total of 40\n",
            "Uploading batch-data/19.csv\n",
            "Uploaded batch-data/19.csv, 11 files out of an estimated total of 40\n",
            "Uploading batch-data/2.csv\n",
            "Uploaded batch-data/2.csv, 12 files out of an estimated total of 40\n",
            "Uploading batch-data/20.csv\n",
            "Uploaded batch-data/20.csv, 13 files out of an estimated total of 40\n",
            "Uploading batch-data/21.csv\n",
            "Uploaded batch-data/21.csv, 14 files out of an estimated total of 40\n",
            "Uploading batch-data/22.csv\n",
            "Uploaded batch-data/22.csv, 15 files out of an estimated total of 40\n",
            "Uploading batch-data/23.csv\n",
            "Uploaded batch-data/23.csv, 16 files out of an estimated total of 40\n",
            "Uploading batch-data/24.csv\n",
            "Uploaded batch-data/24.csv, 17 files out of an estimated total of 40\n",
            "Uploading batch-data/25.csv\n",
            "Uploaded batch-data/25.csv, 18 files out of an estimated total of 40\n",
            "Uploading batch-data/26.csv\n",
            "Uploaded batch-data/26.csv, 19 files out of an estimated total of 40\n",
            "Uploading batch-data/27.csv\n",
            "Uploaded batch-data/27.csv, 20 files out of an estimated total of 40\n",
            "Uploading batch-data/28.csv\n",
            "Uploaded batch-data/28.csv, 21 files out of an estimated total of 40\n",
            "Uploading batch-data/29.csv\n",
            "Uploaded batch-data/29.csv, 22 files out of an estimated total of 40\n",
            "Uploading batch-data/3.csv\n",
            "Uploaded batch-data/3.csv, 23 files out of an estimated total of 40\n",
            "Uploading batch-data/30.csv\n",
            "Uploaded batch-data/30.csv, 24 files out of an estimated total of 40\n",
            "Uploading batch-data/31.csv\n",
            "Uploaded batch-data/31.csv, 25 files out of an estimated total of 40\n",
            "Uploading batch-data/32.csv\n",
            "Uploaded batch-data/32.csv, 26 files out of an estimated total of 40\n",
            "Uploading batch-data/33.csv\n",
            "Uploaded batch-data/33.csv, 27 files out of an estimated total of 40\n",
            "Uploading batch-data/34.csv\n",
            "Uploaded batch-data/34.csv, 28 files out of an estimated total of 40\n",
            "Uploading batch-data/35.csv\n",
            "Uploaded batch-data/35.csv, 29 files out of an estimated total of 40\n",
            "Uploading batch-data/36.csv\n",
            "Uploaded batch-data/36.csv, 30 files out of an estimated total of 40\n",
            "Uploading batch-data/37.csv\n",
            "Uploaded batch-data/37.csv, 31 files out of an estimated total of 40\n",
            "Uploading batch-data/38.csv\n",
            "Uploaded batch-data/38.csv, 32 files out of an estimated total of 40\n",
            "Uploading batch-data/39.csv\n",
            "Uploaded batch-data/39.csv, 33 files out of an estimated total of 40\n",
            "Uploading batch-data/4.csv\n",
            "Uploaded batch-data/4.csv, 34 files out of an estimated total of 40\n",
            "Uploading batch-data/40.csv\n",
            "Uploaded batch-data/40.csv, 35 files out of an estimated total of 40\n",
            "Uploading batch-data/5.csv\n",
            "Uploaded batch-data/5.csv, 36 files out of an estimated total of 40\n",
            "Uploading batch-data/6.csv\n",
            "Uploaded batch-data/6.csv, 37 files out of an estimated total of 40\n",
            "Uploading batch-data/7.csv\n",
            "Uploaded batch-data/7.csv, 38 files out of an estimated total of 40\n",
            "Uploading batch-data/8.csv\n",
            "Uploaded batch-data/8.csv, 39 files out of an estimated total of 40\n",
            "Uploading batch-data/9.csv\n",
            "Uploaded batch-data/9.csv, 40 files out of an estimated total of 40\n",
            "Uploaded 40 files\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006515711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model\n",
        "There are categorical variables in the dataset which can be either converted into indices or one-hot encoding. Tree based work\n",
        "better with indicies. So, we have used R formula transformation for SVM and Logistic Regression. For tree based models, \n",
        "we have used only numberical columns and indices columns.\n",
        "\n",
        "A custom Transformer was used to rename columns and to be used along in pipeline. However, there were some problems in integrating\n",
        "the custom transformer class in scoring script due to which we shifted to normal rename operations with Dataframe.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Transformer used in pipelines for renaming columns \n",
        "from pyspark.ml import Transformer\n",
        "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
        "\n",
        "\n",
        "class ColumnRenamer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
        "    '''\n",
        "    Renames the following columns in the dataframe: \n",
        "    employment variation rate\n",
        "    consumer price index\n",
        "    consumer confidence index \n",
        "    number of employees \n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ColumnRenamer, self).__init__()\n",
        "        self.columnsToBeRenamed = {\n",
        "            'emp.var.rate':'emp_var_rate',\n",
        "            'cons.price.idx':'cons_price_idx',\n",
        "            'cons.conf.idx':'cons_conf_idx',\n",
        "            'nr.employed':'nr_employed'}\n",
        "\n",
        "    def _transform(self, df):\n",
        "        for key in self.columnsToBeRenamed.keys():\n",
        "            df = df.withColumnRenamed(key, self.columnsToBeRenamed[key])\n",
        "        return df    \n",
        "rename_columns = ColumnRenamer()\n",
        "\n",
        "\n",
        "# Uses R Formula for automatic conversion of categorical labels to 1 hot encoding\n",
        "from pyspark.ml.feature import RFormula\n",
        "rFormula = RFormula(formula=\"y ~ .\", featuresCol=\"features\", labelCol=\"label\", handleInvalid=\"skip\")\n",
        "\n",
        "# Uses String Indexer and Numeric Columns only for Tree Based Classifiers\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "example_df = rename_columns.transform(trainDF)\n",
        "categorialColumns = [colname for (colname, dataType) in example_df.dtypes if ((dataType==\"string\") and (colname!=\"y\"))]\n",
        "stringIndexer = StringIndexer(inputCols=categorialColumns, outputCols=[c + \"Index\" for c in categorialColumns])\n",
        "oheEncoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[c + \"ohe\" for c in categorialColumns])\n",
        "label_stringIdx = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "numericColumns = [colname for (colname, dataType) in example_df.dtypes if (dataType==\"int\" or dataType==\"float\" or dataType==\"double\")]\n",
        "assembledInputs = numericColumns + [c + \"Index\" for c in categorialColumns]\n",
        "vecAssembler = VectorAssembler(inputCols=assembledInputs, outputCol=\"features\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006516287
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models are trained and stored in local path in folder called `model`. Then they are registered in AML workspace. We use Reciever Operating Characteristics\n",
        "(ROC) curve, Precision Recall curve and accuracy for evaluating the models.\n",
        "\n",
        "We log the models and metrics using MLflow."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import mlflow.spark\n",
        "import pandas as pd\n",
        "\n",
        "# For Tracking Models\n",
        "model_num=1\n",
        "pipelineModel = None\n",
        "\n",
        "# Evaluators for performance metrics\n",
        "bevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
        "mevaluator = MulticlassClassificationEvaluator()\n",
        "\n",
        "# Rename Columns\n",
        "columnsToBeRenamed = {'emp.var.rate':'emp_var_rate','cons.price.idx':'cons_price_idx','cons.conf.idx':'cons_conf_idx','nr.employed':'nr_employed'}\n",
        "for key in columnsToBeRenamed.keys():\n",
        "    trainDF = trainDF.withColumnRenamed(key, columnsToBeRenamed[key])\n",
        "for key in columnsToBeRenamed.keys():\n",
        "    testDF = testDF.withColumnRenamed(key, columnsToBeRenamed[key])\n",
        "\n",
        "# Non Tree Based Models\n",
        "non_tree_models = [LogisticRegression(), LinearSVC()]\n",
        "for model in non_tree_models:\n",
        "    non_tree_pipeline = Pipeline(stages=[rFormula, model])\n",
        "    pipelineModel = non_tree_pipeline.fit(trainDF)\n",
        "    predDF = pipelineModel.transform(testDF)\n",
        "\n",
        "    modelName =str(model_num)+'-'+model.__class__.__name__\n",
        "    accuracy = mevaluator.setMetricName(\"accuracy\").evaluate(predDF)\n",
        "    roc = bevaluator.setMetricName(\"areaUnderROC\").evaluate(predDF)\n",
        "    pr = bevaluator.setMetricName(\"areaUnderPR\").evaluate(predDF)\n",
        "    model_num += 1\n",
        "\n",
        "\n",
        "    # Log metrics and model\n",
        "    mlflow.spark.log_model(pipelineModel, modelName)\n",
        "    mlflow.log_metrics({\"modelNum\":model_num, \"accuracy\":accuracy, \"areaUnderROC\":roc, \"areaUnderPR\":pr})\n",
        "    print(\"Training complete:\",modelName)\n",
        "\n",
        "# Tree Based Models\n",
        "tree_models = [DecisionTreeClassifier(), RandomForestClassifier(), GBTClassifier()]\n",
        "for model in tree_models:\n",
        "    tree_pipeline = Pipeline(stages=[stringIndexer, oheEncoder, label_stringIdx, vecAssembler,model])\n",
        "    pipelineModel = tree_pipeline.fit(trainDF)\n",
        "    predDF = pipelineModel.transform(testDF)\n",
        "\n",
        "    modelName = str(model_num)+'-'+model.__class__.__name__\n",
        "    accuracy = mevaluator.setMetricName(\"accuracy\").evaluate(predDF)\n",
        "    roc = bevaluator.setMetricName(\"areaUnderROC\").evaluate(predDF)\n",
        "    pr = bevaluator.setMetricName(\"areaUnderPR\").evaluate(predDF)\n",
        "    model_num += 1\n",
        "\n",
        "    # Log metrics and model\n",
        "    mlflow.spark.log_model(pipelineModel, modelName)\n",
        "    mlflow.log_metrics({\"modelNum\":model_num, \"accuracy\":accuracy, \"areaUnderROC\":roc, \"areaUnderPR\":pr})\n",
        "    print(\"Training complete:\",modelName)\n",
        "\n",
        "\n",
        "pipelineModel.save('model')\n",
        "\n",
        "from azureml.core import Model\n",
        "Model.register(\n",
        "    workspace=ws,\n",
        "    model_path='model/',\n",
        "    model_name='pyspark-batch-leads-model',\n",
        ")\n",
        "\n",
        "mlflow.end_run()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete: 1-LogisticRegression\n",
            "Training complete: 2-LinearSVC\n",
            "Training complete: 3-DecisionTreeClassifier\n",
            "Training complete: 4-RandomForestClassifier\n",
            "Training complete: 5-GBTClassifier\n",
            "Registering model pyspark-batch-leads-model\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006734924
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Compute\n",
        "We create compute which is to be used for running batch inference jobs."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# Compute params\r\n",
        "compute_name = 'rohan-vm-cluster'\r\n",
        "inference_cluster = None\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    inference_cluster = ComputeTarget(ws, compute_name)\r\n",
        "    print(\"Using existing cluster.\")\r\n",
        "else:\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(\r\n",
        "            vm_size ='STANDARD_DS11_V2', \r\n",
        "            max_nodes=2 )\r\n",
        "        inference_cluster = ComputeTarget.create(ws, compute_name, compute_config)\r\n",
        "        inference_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    print(\"Cluster created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing cluster.\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006737892
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring Script\n",
        "We create a folder called `batch-pipeline` to save `environment.yml` file and `scoring script` for the pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for storing batch-pipeline files\n",
        "batch_folder = './batch-pipeline'\n",
        "os.makedirs(batch_folder, exist_ok=True)\n",
        "print(\"Folder created!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created!\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006738128
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 'batch-pipeline/batch_environment.yml'\n",
        "name: mlflow-environment\n",
        "channels:\n",
        "  - defaults\n",
        "  - anaconda\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.6\n",
        "  - scikit-learn\n",
        "  - pip\n",
        "  - pandas\n",
        "  - numpy\n",
        "  - openjdk\n",
        "  - pip:\n",
        "    - pyspark\n",
        "    - mlflow\n",
        "    - azureml-mlflow\n",
        "    - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing batch-pipeline/batch_environment.yml\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 'batch-pipeline/score.py'\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Model\r\n",
        "from pyspark.ml import PipelineModel\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model, columnsToBeRenamed, spark\r\n",
        "    spark = SparkSession.builder.getOrCreate()\r\n",
        "    model_path = Model.get_model_path('pyspark-batch-leads-model')\r\n",
        "    model= PipelineModel.load(model_path)\r\n",
        "    columnsToBeRenamed = {'emp.var.rate':'emp_var_rate','cons.price.idx':'cons_price_idx','cons.conf.idx':'cons_conf_idx','nr.employed':'nr_employed'}\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        df = spark.read.csv(path=f,header=\"true\",inferSchema=\"true\",sep=\",\").drop('_c0')\r\n",
        "        for key in columnsToBeRenamed.keys():\r\n",
        "            df = df.withColumnRenamed(key, columnsToBeRenamed[key]) \r\n",
        "        prediction = model.transform(df).select('prediction').toPandas().prediction.map({0.0:\"no\",1.0:\"yes\"}).to_numpy()\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction))\r\n",
        "    return resultList\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing batch-pipeline/score.py\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625970033791
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Pipeline\n",
        "We create a batch inference pipeline with ParallelRunStep. ParallelRunStep parallelizes batch operations."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(name=\"experiment_env\", file_path=\"batch-pipeline/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration ready.\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006738735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory='batch-pipeline/',\r\n",
        "    entry_script=\"score.py\",\r\n",
        "    mini_batch_size=\"5\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=batch_env,\r\n",
        "    compute_target=inference_cluster,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-score-leads',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[batch_data_set.as_named_input('leads_batch')],\r\n",
        "    output=output_dir,\r\n",
        "    arguments=[],\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps defined\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626006738923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(workspace=ws, name='leads-batch-pipeline').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626007243655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch predictions from run\n",
        "A batch inference pipeline coelsce data from multiple nodes in cluster to a single file called `inference` in the pipeline's output.\n",
        "\n",
        "The result of batch inference pipeline is downloaded from the blob storage to local storage\n",
        "in `leads-results` folder. We look for the file `parallel_run_step.txt` in `leads-results` and load it as pandas dataframe.\n",
        "Later on, we write the final leads as csv in `leads-results` folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Remove the local results folder if left over from a previous run\n",
        "result_file = None\n",
        "shutil.rmtree('leads-results', ignore_errors=True)\n",
        "\n",
        "# Get the run for the first step and download its output\n",
        "prediction_run = next(pipeline_run.get_children())\n",
        "prediction_output = prediction_run.get_output_data('inferences')\n",
        "prediction_output.download(local_path='leads-results')\n",
        "\n",
        "# Traverse the folder hierarchy and find the results file\n",
        "for root, dirs, files in os.walk('leads-results'):\n",
        "    for file in files:\n",
        "        if file.endswith('parallel_run_step.txt'):\n",
        "            result_file = os.path.join(root,file)\n",
        "\n",
        "# cleanup output format\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
        "df.columns = [\"File\", \"Prediction\"]\n",
        "df.to_csv(\"leads-results/leads.csv\", header=True,index=False)\n",
        "# Display the first 20 results\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "      File                                         Prediction\n0    1.csv   ['no' 'no' 'yes' 'no' 'no' 'yes' 'no' 'no' 'n...\n1   10.csv   ['no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no...\n2   11.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n3   12.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n4   13.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n5   14.csv   ['no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no...\n6   15.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n7   16.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n8   17.csv   ['yes' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'n...\n9   18.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n10  19.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no...\n11   2.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes...\n12  20.csv   ['yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no...\n13  21.csv   ['no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no...\n14  22.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n15  23.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n16  24.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n17  25.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...\n18  26.csv   ['no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no...\n19  27.csv   ['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.csv</td>\n      <td>['no' 'no' 'yes' 'no' 'no' 'yes' 'no' 'no' 'n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.csv</td>\n      <td>['no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.csv</td>\n      <td>['no' 'yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>15.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>16.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>17.csv</td>\n      <td>['yes' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'n...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>18.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>19.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'yes' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'yes...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>20.csv</td>\n      <td>['yes' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>21.csv</td>\n      <td>['no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>22.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>23.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>24.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>25.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>26.csv</td>\n      <td>['no' 'no' 'no' 'yes' 'no' 'no' 'no' 'no' 'no...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>27.csv</td>\n      <td>['no' 'no' 'no' 'no' 'no' 'no' 'no' 'no' 'no'...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626007245381
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Publish Pipeline\n",
        "The pipeline is published online so that it can be consumed by user with the help of authentication toke."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(name='leads-batch-pipeline', description='Batch scoring of leads data from UCI', version='1.0')\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://centralindia.api.azureml.ms/pipelines/v1.0/subscriptions/23416925-66df-470c-b651-f378856d8ad7/resourceGroups/rohan-rg/providers/Microsoft.MachineLearningServices/workspaces/rohan-ws/PipelineRuns/PipelineSubmit/eedecb53-a277-43d7-a5ef-f31e71dba0b0\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626007248392
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Pipeline\n",
        "We use HTTP request to run the deployed pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.pipeline.core.run import PipelineRun\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "import requests\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, headers=auth_header, json={\"ExperimentName\": \"leads-batch-pipeline\"})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "\r\n",
        "published_pipeline_run = PipelineRun(ws.experiments['leads-batch-pipeline'], run_id)\r\n",
        "published_pipeline_run.wait_for_completion(show_output=False)\r\n",
        "\r\n",
        "print(\"OK\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1626008032392
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}