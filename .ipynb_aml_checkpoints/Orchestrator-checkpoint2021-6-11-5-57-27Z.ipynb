{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from azureml.core import Workspace, Experiment\r\n",
        "import mlflow\r\n",
        "\r\n",
        "# Setup Azure Workspace\r\n",
        "ws = Workspace.from_config()\r\n",
        "experiment_name = 'leads-pyspark-train'\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
        "\r\n",
        "# Start MLflow Experiment\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "run = mlflow.start_run()\r\n",
        "\r\n",
        "# Get default datastore\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Get Spark session\r\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625974117242
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and Upload Batch Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "df = spark.read.csv(\r\n",
        "    path='data/bank-additional-full.csv',\r\n",
        "    header=\"true\",\r\n",
        "    inferSchema=\"true\",\r\n",
        "    sep=\";\")\r\n",
        "trainDF, testDF, batchDF = df.randomSplit([.7, .29, .01], seed=999)\r\n",
        "batchData = batchDF.toPandas()\r\n",
        "\r\n",
        "# Create a folder\r\n",
        "batch_folder = './batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "# Save each sample as a separate file\r\n",
        "print(\"Saving files...\")\r\n",
        "x = 0\r\n",
        "y = 10\r\n",
        "for i in range(int(batchDF.count()/10)):\r\n",
        "    filename = str(i+1) + '.csv'\r\n",
        "    writeData=batchData[x:y]\r\n",
        "    writeData.to_csv(os.path.join(batch_folder, filename), sep=\",\")\r\n",
        "    x+=10\r\n",
        "    y+=10\r\n",
        "\r\n",
        "print(\"files saved!\")\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \r\n",
        "                                             name='leads-batch-data',\r\n",
        "                                             description='batch data for Marketing Leads UCI',\r\n",
        "                                             create_new_version=True)\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created!\n",
            "Saving files...\n",
            "files saved!\n",
            "Uploading files to datastore...\n",
            "Uploading an estimated of 40 files\n",
            "Uploading batch-data/1.csv\n",
            "Uploaded batch-data/1.csv, 1 files out of an estimated total of 40\n",
            "Uploading batch-data/10.csv\n",
            "Uploaded batch-data/10.csv, 2 files out of an estimated total of 40\n",
            "Uploading batch-data/11.csv\n",
            "Uploaded batch-data/11.csv, 3 files out of an estimated total of 40\n",
            "Uploading batch-data/12.csv\n",
            "Uploaded batch-data/12.csv, 4 files out of an estimated total of 40\n",
            "Uploading batch-data/13.csv\n",
            "Uploaded batch-data/13.csv, 5 files out of an estimated total of 40\n",
            "Uploading batch-data/14.csv\n",
            "Uploaded batch-data/14.csv, 6 files out of an estimated total of 40\n",
            "Uploading batch-data/15.csv\n",
            "Uploaded batch-data/15.csv, 7 files out of an estimated total of 40\n",
            "Uploading batch-data/16.csv\n",
            "Uploaded batch-data/16.csv, 8 files out of an estimated total of 40\n",
            "Uploading batch-data/17.csv\n",
            "Uploaded batch-data/17.csv, 9 files out of an estimated total of 40\n",
            "Uploading batch-data/18.csv\n",
            "Uploaded batch-data/18.csv, 10 files out of an estimated total of 40\n",
            "Uploading batch-data/19.csv\n",
            "Uploaded batch-data/19.csv, 11 files out of an estimated total of 40\n",
            "Uploading batch-data/2.csv\n",
            "Uploaded batch-data/2.csv, 12 files out of an estimated total of 40\n",
            "Uploading batch-data/20.csv\n",
            "Uploaded batch-data/20.csv, 13 files out of an estimated total of 40\n",
            "Uploading batch-data/21.csv\n",
            "Uploaded batch-data/21.csv, 14 files out of an estimated total of 40\n",
            "Uploading batch-data/22.csv\n",
            "Uploaded batch-data/22.csv, 15 files out of an estimated total of 40\n",
            "Uploading batch-data/23.csv\n",
            "Uploaded batch-data/23.csv, 16 files out of an estimated total of 40\n",
            "Uploading batch-data/24.csv\n",
            "Uploaded batch-data/24.csv, 17 files out of an estimated total of 40\n",
            "Uploading batch-data/25.csv\n",
            "Uploaded batch-data/25.csv, 18 files out of an estimated total of 40\n",
            "Uploading batch-data/26.csv\n",
            "Uploaded batch-data/26.csv, 19 files out of an estimated total of 40\n",
            "Uploading batch-data/27.csv\n",
            "Uploaded batch-data/27.csv, 20 files out of an estimated total of 40\n",
            "Uploading batch-data/28.csv\n",
            "Uploaded batch-data/28.csv, 21 files out of an estimated total of 40\n",
            "Uploading batch-data/29.csv\n",
            "Uploaded batch-data/29.csv, 22 files out of an estimated total of 40\n",
            "Uploading batch-data/3.csv\n",
            "Uploaded batch-data/3.csv, 23 files out of an estimated total of 40\n",
            "Uploading batch-data/30.csv\n",
            "Uploaded batch-data/30.csv, 24 files out of an estimated total of 40\n",
            "Uploading batch-data/31.csv\n",
            "Uploaded batch-data/31.csv, 25 files out of an estimated total of 40\n",
            "Uploading batch-data/32.csv\n",
            "Uploaded batch-data/32.csv, 26 files out of an estimated total of 40\n",
            "Uploading batch-data/33.csv\n",
            "Uploaded batch-data/33.csv, 27 files out of an estimated total of 40\n",
            "Uploading batch-data/34.csv\n",
            "Uploaded batch-data/34.csv, 28 files out of an estimated total of 40\n",
            "Uploading batch-data/35.csv\n",
            "Uploaded batch-data/35.csv, 29 files out of an estimated total of 40\n",
            "Uploading batch-data/36.csv\n",
            "Uploaded batch-data/36.csv, 30 files out of an estimated total of 40\n",
            "Uploading batch-data/37.csv\n",
            "Uploaded batch-data/37.csv, 31 files out of an estimated total of 40\n",
            "Uploading batch-data/38.csv\n",
            "Uploaded batch-data/38.csv, 32 files out of an estimated total of 40\n",
            "Uploading batch-data/39.csv\n",
            "Uploaded batch-data/39.csv, 33 files out of an estimated total of 40\n",
            "Uploading batch-data/4.csv\n",
            "Uploaded batch-data/4.csv, 34 files out of an estimated total of 40\n",
            "Uploading batch-data/40.csv\n",
            "Uploaded batch-data/40.csv, 35 files out of an estimated total of 40\n",
            "Uploading batch-data/5.csv\n",
            "Uploaded batch-data/5.csv, 36 files out of an estimated total of 40\n",
            "Uploading batch-data/6.csv\n",
            "Uploaded batch-data/6.csv, 37 files out of an estimated total of 40\n",
            "Uploading batch-data/7.csv\n",
            "Uploaded batch-data/7.csv, 38 files out of an estimated total of 40\n",
            "Uploading batch-data/8.csv\n",
            "Uploaded batch-data/8.csv, 39 files out of an estimated total of 40\n",
            "Uploading batch-data/9.csv\n",
            "Uploaded batch-data/9.csv, 40 files out of an estimated total of 40\n",
            "Uploaded 40 files\n",
            "Done!\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625974133088
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Transformer used in pipelines for renaming columns \n",
        "from pyspark.ml import Transformer\n",
        "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
        "\n",
        "class ColumnRenamer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
        "    '''\n",
        "    Renames the following columns in the dataframe: \n",
        "    employment variation rate\n",
        "    consumer price index\n",
        "    consumer confidence index \n",
        "    number of employees \n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ColumnRenamer, self).__init__()\n",
        "        self.columnsToBeRenamed = {\n",
        "            'emp.var.rate':'emp_var_rate',\n",
        "            'cons.price.idx':'cons_price_idx',\n",
        "            'cons.conf.idx':'cons_conf_idx',\n",
        "            'nr.employed':'nr_employed'}\n",
        "\n",
        "    def _transform(self, df):\n",
        "        for key in self.columnsToBeRenamed.keys():\n",
        "            df = df.withColumnRenamed(key, self.columnsToBeRenamed[key])\n",
        "        return df    \n",
        "rename_columns = ColumnRenamer()\n",
        "\n",
        "# Uses R Formula for automatic conversion of categorical labels to 1 hot encoding\n",
        "from pyspark.ml.feature import RFormula\n",
        "rFormula = RFormula(formula=\"y ~ .\", featuresCol=\"features\", labelCol=\"label\", handleInvalid=\"skip\")\n",
        "\n",
        "# Uses String Indexer and Numeric Columns only for Tree Based Classifiers\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "example_df = rename_columns.transform(trainDF)\n",
        "categorialColumns = [colname for (colname, dataType) in example_df.dtypes if ((dataType==\"string\") and (colname!=\"y\"))]\n",
        "stringIndexer = StringIndexer(inputCols=categorialColumns, outputCols=[c + \"Index\" for c in categorialColumns])\n",
        "oheEncoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[c + \"ohe\" for c in categorialColumns])\n",
        "label_stringIdx = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
        "numericColumns = [colname for (colname, dataType) in example_df.dtypes if (dataType==\"int\" or dataType==\"float\" or dataType==\"double\")]\n",
        "assembledInputs = numericColumns + [c + \"Index\" for c in categorialColumns]\n",
        "vecAssembler = VectorAssembler(inputCols=assembledInputs, outputCol=\"features\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625974133461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LinearSVC\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import mlflow.spark\n",
        "import pandas as pd\n",
        "\n",
        "# For Tracking Models\n",
        "model_num=1\n",
        "pipelineModel = None\n",
        "\n",
        "# Evaluators for performance metrics\n",
        "bevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\n",
        "mevaluator = MulticlassClassificationEvaluator()\n",
        "\n",
        "# Non Tree Based Models\n",
        "non_tree_models = [LogisticRegression(), LinearSVC()]\n",
        "for model in non_tree_models:\n",
        "    non_tree_pipeline = Pipeline(stages=[rename_columns, rFormula, model])\n",
        "    pipelineModel = non_tree_pipeline.fit(trainDF)\n",
        "    predDF = pipelineModel.transform(testDF)\n",
        "\n",
        "    modelName =str(model_num)+'-'+model.__class__.__name__\n",
        "    accuracy = mevaluator.setMetricName(\"accuracy\").evaluate(predDF)\n",
        "    roc = bevaluator.setMetricName(\"areaUnderROC\").evaluate(predDF)\n",
        "    pr = bevaluator.setMetricName(\"areaUnderPR\").evaluate(predDF)\n",
        "    model_num += 1\n",
        "\n",
        "\n",
        "    # Log metrics and model\n",
        "    mlflow.spark.log_model(pipelineModel, modelName)\n",
        "    mlflow.log_metrics({\"modelNum\":model_num, \"accuracy\":accuracy, \"areaUnderROC\":roc, \"areaUnderPR\":pr})\n",
        "    print(\"Training complete:\",modelName)\n",
        "\n",
        "# Tree Based Models\n",
        "tree_models = [DecisionTreeClassifier(), RandomForestClassifier(), GBTClassifier()]\n",
        "for model in tree_models:\n",
        "    tree_pipeline = Pipeline(stages=[rename_columns, stringIndexer, oheEncoder, label_stringIdx, vecAssembler,model])\n",
        "    pipelineModel = tree_pipeline.fit(trainDF)\n",
        "    predDF = pipelineModel.transform(testDF)\n",
        "\n",
        "    modelName = str(model_num)+'-'+model.__class__.__name__\n",
        "    accuracy = mevaluator.setMetricName(\"accuracy\").evaluate(predDF)\n",
        "    roc = bevaluator.setMetricName(\"areaUnderROC\").evaluate(predDF)\n",
        "    pr = bevaluator.setMetricName(\"areaUnderPR\").evaluate(predDF)\n",
        "    model_num += 1\n",
        "\n",
        "    # Log metrics and model\n",
        "    mlflow.spark.log_model(pipelineModel, modelName)\n",
        "    mlflow.log_metrics({\"modelNum\":model_num, \"accuracy\":accuracy, \"areaUnderROC\":roc, \"areaUnderPR\":pr})\n",
        "    print(\"Training complete:\",modelName)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete: 1-LogisticRegression\n",
            "Training complete: 2-LinearSVC\n",
            "Training complete: 3-DecisionTreeClassifier\n",
            "Training complete: 4-RandomForestClassifier\n",
            "Training complete: 5-GBTClassifier\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625974340045
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "gbt = GBTClassifier()\n",
        "gbt_pipeline = Pipeline(stages=[rename_columns, stringIndexer, oheEncoder, label_stringIdx, vecAssembler, gbt])\n",
        "paramGrid = ParamGridBuilder().addGrid(gbt.maxDepth,[5,10]).build()\n",
        "    \n",
        "cv = CrossValidator(estimator=gbt_pipeline, estimatorParamMaps=paramGrid, evaluator=mevaluator, numFolds=5)\n",
        "cvModel = cv.fit(trainDF)\n",
        "predictions = cvModel.transform(testDF)\n",
        "bevaluator.evaluate(predictions)\n",
        "'''\n",
        "\n",
        "pipelineModel.save('model')\n",
        "\n",
        "from azureml.core import Model\n",
        "Model.register(\n",
        "    workspace=ws,\n",
        "    model_path='model/',\n",
        "    model_name='pyspark-batch-leads-model',\n",
        ")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model pyspark-batch-leads-model\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625974362348
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# Compute params\r\n",
        "compute_name = 'rohan-vm-cluster'\r\n",
        "inference_cluster = None\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    inference_cluster = ComputeTarget(ws, compute_name)\r\n",
        "    print(\"Using existing cluster.\")\r\n",
        "else:\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(\r\n",
        "            vm_size ='STANDARD_DS11_V2', \r\n",
        "            max_nodes=2 )\r\n",
        "        inference_cluster = ComputeTarget.create(ws, compute_name, compute_config)\r\n",
        "        inference_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    print(\"Cluster created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing cluster.\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625975189549
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring Script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 'batch-pipeline/score.py'\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Model\r\n",
        "from pyspark.ml import PipelineModel\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "class ColumnRenamer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\r\n",
        "    '''\r\n",
        "    Renames the following columns in the dataframe: \r\n",
        "    employment variation rate\r\n",
        "    consumer price index\r\n",
        "    consumer confidence index \r\n",
        "    number of employees \r\n",
        "    '''\r\n",
        "    def __init__(self):\r\n",
        "        super(ColumnRenamer, self).__init__()\r\n",
        "        self.columnsToBeRenamed = {\r\n",
        "            'emp.var.rate':'emp_var_rate',\r\n",
        "            'cons.price.idx':'cons_price_idx',\r\n",
        "            'cons.conf.idx':'cons_conf_idx',\r\n",
        "            'nr.employed':'nr_employed'}\r\n",
        "\r\n",
        "    def _transform(self, df):\r\n",
        "        for key in self.columnsToBeRenamed.keys():\r\n",
        "            df = df.withColumnRenamed(key, self.columnsToBeRenamed[key])\r\n",
        "        return df    \r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    rename_columns = ColumnRenamer()\r\n",
        "    spark = SparkSession.builder.getOrCreate()\r\n",
        "    model_path = Model.get_model_path('pyspark-batch-leads-model')\r\n",
        "    model= PipelineModel.load(model_path)\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        df = spark.read.csv(path=f,header=\"true\",inferSchema=\"true\",sep=\",\").drop('_c0')\r\n",
        "        prediction = model.transform(df).select('prediction').toPandas().prediction.map({0.0:\"no\",1.0:\"yes\"}).to_numpy()\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction))\r\n",
        "    return resultList\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting batch-pipeline/score.py\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625970033791
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(name=\"experiment_env\", file_path=\"batch-pipeline/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration ready.\n"
          ]
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625982030908
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory='batch-pipeline/',\r\n",
        "    entry_script=\"score.py\",\r\n",
        "    mini_batch_size=\"5\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=batch_env,\r\n",
        "    compute_target=inference_cluster,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-score-leads',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[batch_data_set.as_named_input('leads_batch')],\r\n",
        "    output=output_dir,\r\n",
        "    arguments=[],\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps defined\n"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625982033562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(workspace=ws, name='leads-batch-pipeline').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step batch-score-leads [32df8786][a72035e0-b985-425f-b32b-86e02f595d15], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 2fc25cd9-6810-43e0-89e6-bddae80c1641\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/2fc25cd9-6810-43e0-89e6-bddae80c1641?wsid=/subscriptions/23416925-66df-470c-b651-f378856d8ad7/resourcegroups/rohan-rg/workspaces/rohan-ws&tid=13715ad3-e049-4909-899b-f9e22f99b1a5\n",
            "PipelineRunId: 2fc25cd9-6810-43e0-89e6-bddae80c1641\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/2fc25cd9-6810-43e0-89e6-bddae80c1641?wsid=/subscriptions/23416925-66df-470c-b651-f378856d8ad7/resourcegroups/rohan-rg/workspaces/rohan-ws&tid=13715ad3-e049-4909-899b-f9e22f99b1a5\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: c3e422d5-b7d0-4eca-b33d-73a0a752d626\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c3e422d5-b7d0-4eca-b33d-73a0a752d626?wsid=/subscriptions/23416925-66df-470c-b651-f378856d8ad7/resourcegroups/rohan-rg/workspaces/rohan-ws&tid=13715ad3-e049-4909-899b-f9e22f99b1a5\n",
            "StepRun( batch-score-leads ) Status: NotStarted\n",
            "StepRun( batch-score-leads ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "2021/07/11 05:41:06 Downloading source code...\n",
            "2021/07/11 05:41:08 Finished downloading source code\n",
            "2021/07/11 05:41:08 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2021/07/11 05:41:09 Successfully set up Docker network: acb_default_network\n",
            "2021/07/11 05:41:09 Setting up Docker configuration...\n",
            "2021/07/11 05:41:10 Successfully set up Docker configuration\n",
            "2021/07/11 05:41:10 Logging in to registry: rohancr.azurecr.io\n",
            "2021/07/11 05:41:11 Successfully logged into rohancr.azurecr.io\n",
            "2021/07/11 05:41:11 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/07/11 05:41:11 Scanning for dependencies...\n",
            "2021/07/11 05:41:12 Successfully scanned dependencies\n",
            "2021/07/11 05:41:12 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
            "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
            "4bbfd2c87b75: Pulling fs layer\n",
            "d2e110be24e1: Pulling fs layer\n",
            "889a7173dcfe: Pulling fs layer\n",
            "7a7a145ebf57: Pulling fs layer\n",
            "1ae81884420d: Pulling fs layer\n",
            "fcdf07e25452: Pulling fs layer\n",
            "95262654cd7f: Pulling fs layer\n",
            "520cb0fab4f5: Pulling fs layer\n",
            "00c1c086d027: Pulling fs layer\n",
            "282c4a3b6fb6: Pulling fs layer\n",
            "f4201c7ca826: Pulling fs layer\n",
            "7a7a145ebf57: Waiting\n",
            "1ae81884420d: Waiting\n",
            "fcdf07e25452: Waiting\n",
            "95262654cd7f: Waiting\n",
            "520cb0fab4f5: Waiting\n",
            "00c1c086d027: Waiting\n",
            "282c4a3b6fb6: Waiting\n",
            "f4201c7ca826: Waiting\n",
            "d2e110be24e1: Verifying Checksum\n",
            "d2e110be24e1: Download complete\n",
            "889a7173dcfe: Verifying Checksum\n",
            "889a7173dcfe: Download complete\n",
            "4bbfd2c87b75: Verifying Checksum\n",
            "4bbfd2c87b75: Download complete\n",
            "fcdf07e25452: Verifying Checksum\n",
            "fcdf07e25452: Download complete\n",
            "1ae81884420d: Verifying Checksum\n",
            "1ae81884420d: Download complete\n",
            "520cb0fab4f5: Verifying Checksum\n",
            "520cb0fab4f5: Download complete\n",
            "7a7a145ebf57: Verifying Checksum\n",
            "7a7a145ebf57: Download complete\n",
            "282c4a3b6fb6: Verifying Checksum\n",
            "282c4a3b6fb6: Download complete\n",
            "95262654cd7f: Verifying Checksum\n",
            "95262654cd7f: Download complete\n",
            "00c1c086d027: Verifying Checksum\n",
            "00c1c086d027: Download complete\n",
            "f4201c7ca826: Verifying Checksum\n",
            "f4201c7ca826: Download complete\n",
            "4bbfd2c87b75: Pull complete\n",
            "d2e110be24e1: Pull complete\n",
            "889a7173dcfe: Pull complete\n",
            "7a7a145ebf57: Pull complete\n",
            "1ae81884420d: Pull complete\n",
            "fcdf07e25452: Pull complete\n",
            "95262654cd7f: Pull complete\n",
            "520cb0fab4f5: Pull complete\n",
            "00c1c086d027: Pull complete\n",
            "282c4a3b6fb6: Pull complete\n",
            "f4201c7ca826: Pull complete\n",
            "Digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1@sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
            " ---> 6ba46986c29e\n",
            "Step 2/18 : USER root\n",
            " ---> Running in 9f9971ff8360\n",
            "Removing intermediate container 9f9971ff8360\n",
            " ---> 6bff293b250e\n",
            "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in f14c075d8529\n",
            "Removing intermediate container f14c075d8529\n",
            " ---> 7b60020ad702\n",
            "Step 4/18 : WORKDIR /\n",
            " ---> Running in 9b171d98a4bd\n",
            "Removing intermediate container 9b171d98a4bd\n",
            " ---> 38305788a1c3\n",
            "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 7295c721cf3c\n",
            "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in 39e644397dbe\n",
            "Removing intermediate container 39e644397dbe\n",
            " ---> 6bdec7121037\n",
            "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> aeaea35323d0\n",
            "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in 5a39e315471c\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... \n",
            "done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "python-3.6.13        | 32.5 MB   |            |   0% \n",
            "python-3.6.13        | 32.5 MB   |            |   0% \n",
            "python-3.6.13        | 32.5 MB   |            |   1% \n",
            "python-3.6.13        | 32.5 MB   | 5          |   6% \n",
            "python-3.6.13        | 32.5 MB   | 9          |   9% \n",
            "python-3.6.13        | 32.5 MB   | #7         |  17% \n",
            "python-3.6.13        | 32.5 MB   | ###4       |  34% \n",
            "python-3.6.13        | 32.5 MB   | #####8     |  59% \n",
            "python-3.6.13        | 32.5 MB   | ########4  |  84% \n",
            "python-3.6.13        | 32.5 MB   | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 103 KB    |            |   0% \n",
            "zlib-1.2.11          | 103 KB    | ########## | 100% \n",
            "\n",
            "intel-openmp-2021.2. | 1.3 MB    |            |   0% \n",
            "intel-openmp-2021.2. | 1.3 MB    | ########## | 100% \n",
            "intel-openmp-2021.2. | 1.3 MB    | ########## | 100% \n",
            "\n",
            "mkl-service-2.3.0    | 52 KB     |            |   0% \n",
            "mkl-service-2.3.0    | 52 KB     | ########## | 100% \n",
            "\n",
            "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
            "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
            "\n",
            "mkl-2020.2           | 138.3 MB  |            |   0% \n",
            "mkl-2020.2           | 138.3 MB  | 2          |   2% \n",
            "mkl-2020.2           | 138.3 MB  | 6          |   7% \n",
            "mkl-2020.2           | 138.3 MB  | #1         |  11% \n",
            "mkl-2020.2           | 138.3 MB  | #5         |  16% \n",
            "mkl-2020.2           | 138.3 MB  | ##1        |  21% \n",
            "mkl-2020.2           | 138.3 MB  | ##6        |  27% \n",
            "mkl-2020.2           | 138.3 MB  | ###2       |  33% \n",
            "mkl-2020.2           | 138.3 MB  | ###8       |  38% \n",
            "mkl-2020.2           | 138.3 MB  | ####3      |  44% \n",
            "mkl-2020.2           | 138.3 MB  | ####9      |  49% \n",
            "mkl-2020.2           | 138.3 MB  | #####4     |  55% \n",
            "mkl-2020.2           | 138.3 MB  | ######     |  61% \n",
            "mkl-2020.2           | 138.3 MB  | ######6    |  67% \n",
            "mkl-2020.2           | 138.3 MB  | #######2   |  73% \n",
            "mkl-2020.2           | 138.3 MB  | #######8   |  79% \n",
            "mkl-2020.2           | 138.3 MB  | ########4  |  84% \n",
            "mkl-2020.2           | 138.3 MB  | #########  |  90% \n",
            "mkl-2020.2           | 138.3 MB  | #########5 |  96% \n",
            "mkl-2020.2           | 138.3 MB  | ########## | 100% \n",
            "\n",
            "readline-8.1         | 362 KB    |            |   0% \n",
            "readline-8.1         | 362 KB    | ########## | 100% \n",
            "\n",
            "wheel-0.36.2         | 33 KB     |            |   0% \n",
            "wheel-0.36.2         | 33 KB     | ########## | 100% \n",
            "\n",
            "mkl_random-1.1.1     | 327 KB    |            |   0% \n",
            "mkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
            "\n",
            "ld_impl_linux-64-2.3 | 586 KB    |            |   0% \n",
            "ld_impl_linux-64-2.3 | 586 KB    | ########## | 100% \n",
            "\n",
            "libgomp-9.3.0        | 311 KB    |            |   0% \n",
            "libgomp-9.3.0        | 311 KB    | ########## | 100% \n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   |            |   0% \n",
            "scipy-1.5.2          | 14.4 MB   | 7          |   8% \n",
            "scipy-1.5.2          | 14.4 MB   | ####3      |  43% \n",
            "scipy-1.5.2          | 14.4 MB   | #########9 |  99% \n",
            "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
            "\n",
            "sqlite-3.36.0        | 990 KB    |            |   0% \n",
            "sqlite-3.36.0        | 990 KB    | ########## | 100% \n",
            "sqlite-3.36.0        | 990 KB    | ########## | 100% \n",
            "\n",
            "threadpoolctl-2.1.0  | 17 KB     |            |   0% \n",
            "threadpoolctl-2.1.0  | 17 KB     | ########## | 100% \n",
            "\n",
            "pip-21.1.3           | 1.8 MB    |            |   0% \n",
            "pip-21.1.3           | 1.8 MB    | #######7   |  78% \n",
            "pip-21.1.3           | 1.8 MB    | ########## | 100% \n",
            "pip-21.1.3           | 1.8 MB    | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 341 KB    |            |   0% \n",
            "xz-5.2.5             | 341 KB    | ########## | 100% \n",
            "\n",
            "libgfortran4-7.5.0   | 995 KB    |            |   0% \n",
            "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
            "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    |            |   0% \n",
            "scikit-learn-0.24.2  | 5.2 MB    | ##3        |  23% \n",
            "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
            "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
            "\n",
            "mkl_fft-1.3.0        | 170 KB    |            |   0% \n",
            "mkl_fft-1.3.0        | 170 KB    | ########## | 100% \n",
            "\n",
            "numpy-1.19.2         | 22 KB     |            |   0% \n",
            "numpy-1.19.2         | 22 KB     | ########## | 100% \n",
            "\n",
            "blas-1.0             | 6 KB      |            |   0% \n",
            "blas-1.0             | 6 KB      | ########## | 100% \n",
            "\n",
            "joblib-1.0.1         | 208 KB    |            |   0% \n",
            "joblib-1.0.1         | 208 KB    | ########## | 100% \n",
            "\n",
            "libffi-3.3           | 50 KB     |            |   0% \n",
            "libffi-3.3           | 50 KB     | ########## | 100% \n",
            "\n",
            "ncurses-6.2          | 817 KB    |            |   0% \n",
            "ncurses-6.2          | 817 KB    | ########## | 100% \n",
            "ncurses-6.2          | 817 KB    | ########## | 100% \n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    |            |   0% \n",
            "pandas-1.1.5         | 8.2 MB    | #3         |  14% \n",
            "pandas-1.1.5         | 8.2 MB    | #######9   |  80% \n",
            "pandas-1.1.5         | 8.2 MB    | ########## | 100% \n",
            "\n",
            "pytz-2021.1          | 181 KB    |            |   0% \n",
            "pytz-2021.1          | 181 KB    | ########## | 100% \n",
            "pytz-2021.1          | 181 KB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.0 MB    |            |   0% \n",
            "tk-8.6.10            | 3.0 MB    | ###9       |  40% \n",
            "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.0 MB    | ########## | 100% \n",
            "\n",
            "six-1.16.0           | 18 KB     |            |   0% \n",
            "six-1.16.0           | 18 KB     | ########## | 100% \n",
            "\n",
            "openssl-1.1.1k       | 2.5 MB    |            |   0% \n",
            "openssl-1.1.1k       | 2.5 MB    | #######6   |  76% \n",
            "openssl-1.1.1k       | 2.5 MB    | ########## | 100% \n",
            "\n",
            "openjdk-8.0.152      | 57.4 MB   |            |   0% \n",
            "openjdk-8.0.152      | 57.4 MB   |            |   0% \n",
            "openjdk-8.0.152      | 57.4 MB   |            |   0% \n",
            "openjdk-8.0.152      | 57.4 MB   |            |   1% \n",
            "openjdk-8.0.152      | 57.4 MB   |            |   1% \n",
            "openjdk-8.0.152      | 57.4 MB   | 1          |   1% \n",
            "openjdk-8.0.152      | 57.4 MB   | 1          |   1% \n",
            "openjdk-8.0.152      | 57.4 MB   | 2          |   2% \n",
            "openjdk-8.0.152      | 57.4 MB   | 2          |   3% \n",
            "openjdk-8.0.152      | 57.4 MB   | 3          |   4% \n",
            "openjdk-8.0.152      | 57.4 MB   | 5          |   5% \n",
            "openjdk-8.0.152      | 57.4 MB   | 6          |   7% \n",
            "openjdk-8.0.152      | 57.4 MB   | 8          |   8% \n",
            "openjdk-8.0.152      | 57.4 MB   | 9          |  10% \n",
            "openjdk-8.0.152      | 57.4 MB   | #          |  11% \n",
            "openjdk-8.0.152      | 57.4 MB   | #2         |  12% \n",
            "openjdk-8.0.152      | 57.4 MB   | #3         |  14% \n",
            "openjdk-8.0.152      | 57.4 MB   | #5         |  15% \n",
            "openjdk-8.0.152      | 57.4 MB   | #6         |  17% \n",
            "openjdk-8.0.152      | 57.4 MB   | #8         |  18% \n",
            "openjdk-8.0.152      | 57.4 MB   | #9         |  20% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##1        |  21% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##2        |  22% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##3        |  24% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##5        |  25% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##6        |  27% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##7        |  28% \n",
            "openjdk-8.0.152      | 57.4 MB   | ##9        |  29% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###        |  31% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###2       |  32% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###3       |  33% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###4       |  35% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###6       |  36% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###7       |  38% \n",
            "openjdk-8.0.152      | 57.4 MB   | ###9       |  39% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####       |  41% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####1      |  42% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####3      |  43% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####4      |  45% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####6      |  46% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####7      |  48% \n",
            "openjdk-8.0.152      | 57.4 MB   | ####8      |  49% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####      |  50% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####1     |  52% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####3     |  53% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####4     |  55% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####5     |  56% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####7     |  57% \n",
            "openjdk-8.0.152      | 57.4 MB   | #####8     |  59% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######     |  60% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######1    |  61% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######2    |  63% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######4    |  64% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######5    |  66% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######7    |  67% \n",
            "openjdk-8.0.152      | 57.4 MB   | ######8    |  69% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######    |  70% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######1   |  72% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######2   |  73% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######4   |  74% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######5   |  76% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######7   |  77% \n",
            "openjdk-8.0.152      | 57.4 MB   | #######8   |  79% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########   |  80% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########1  |  81% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########2  |  83% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########4  |  84% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########5  |  86% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########7  |  87% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########8  |  89% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########9  |  90% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########1 |  91% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########2 |  93% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########4 |  94% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########5 |  96% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########6 |  97% \n",
            "openjdk-8.0.152      | 57.4 MB   | #########8 |  99% \n",
            "openjdk-8.0.152      | 57.4 MB   | ########## | 100% \n",
            "\n",
            "setuptools-52.0.0    | 724 KB    |            |   0% \n",
            "setuptools-52.0.0    | 724 KB    | ########## | 100% \n",
            "setuptools-52.0.0    | 724 KB    | ########## | 100% \n",
            "\n",
            "ca-certificates-2021 | 113 KB    |            |   0% \n",
            "ca-certificates-2021 | 113 KB    | ########## | 100% \n",
            "\n",
            "_openmp_mutex-4.5    | 22 KB     |            |   0% \n",
            "_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
            "\n",
            "numpy-base-1.19.2    | 4.1 MB    |            |   0% \n",
            "numpy-base-1.19.2    | 4.1 MB    | ##8        |  28% \n",
            "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
            "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
            "\n",
            "certifi-2021.5.30    | 139 KB    |            |   0% \n",
            "certifi-2021.5.30    | 139 KB    | ########## | 100% \n",
            "\n",
            "python-dateutil-2.8. | 221 KB    |            |   0% \n",
            "python-dateutil-2.8. | 221 KB    | ########## | 100% \n",
            "\n",
            "libgfortran-ng-7.5.0 | 22 KB     |            |   0% \n",
            "libgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.3.0      | 4.8 MB    |            |   0% \n",
            "libgcc-ng-9.3.0      | 4.8 MB    | ##3        |  24% \n",
            "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
            "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \n",
            "libstdcxx-ng-9.3.0   | 3.1 MB    | ####1      |  42% \n",
            "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... \n",
            "\n",
            "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
            "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
            "\n",
            "    For example:\n",
            "\n",
            "        $ conda install scikit-learn-intelex\n",
            "        $ python -m sklearnex my_application.py\n",
            "\n",
            "    \n",
            "\n",
            "done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.v16v0cj1.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.18.0-py3-none-any.whl (14.2 MB)\n",
            "Collecting azureml-mlflow\n",
            "  Downloading azureml_mlflow-1.32.0-py3-none-any.whl (41 kB)\n",
            "Collecting azureml-defaults\n",
            "  Downloading azureml_defaults-1.32.0-py3-none-any.whl (3.1 kB)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "Collecting protobuf>=3.7.0\n",
            "  Downloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: numpy in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (1.19.2)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "Collecting cloudpickle\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting click>=7.0\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
            "Collecting requests>=2.17.3\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Collecting Flask\n",
            "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: pandas in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (1.1.5)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting sqlparse>=0.3.1\n",
            "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pytz in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (2021.1)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
            "Collecting sqlalchemy\n",
            "  Downloading SQLAlchemy-1.4.20-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: python-dateutil in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (2.8.1)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
            "Collecting tabulate>=0.7.7\n",
            "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six>=1.10.0 in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (1.16.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "Collecting typing-extensions>=3.7.4.0\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from requests>=2.17.3->mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (2021.5.30)\n",
            "Collecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-1.1.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (155 kB)\n",
            "Collecting mlflow-skinny\n",
            "  Downloading mlflow_skinny-1.18.0-py3-none-any.whl (565 kB)\n",
            "Collecting azureml-core~=1.32.0\n",
            "  Downloading azureml_core-1.32.0-py3-none-any.whl (2.2 MB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
            "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
            "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
            "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
            "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-8.0.0-py2.py3-none-any.whl (663 kB)\n",
            "Collecting pyopenssl<21.0.0\n",
            "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting contextlib2<1.0.0\n",
            "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-9.0.0-py2.py3-none-any.whl (312 kB)\n",
            "Collecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "Collecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting azure-core<2.0.0,>=1.15.0\n",
            "  Downloading azure_core-1.16.0-py2.py3-none-any.whl (163 kB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp36-cp36m-manylinux1_x86_64.whl (552 kB)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.7.0-py3-none-any.whl (53 kB)\n",
            "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
            "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
            "Collecting Flask\n",
            "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
            "Collecting azureml-dataset-runtime[fuse]~=1.32.0\n",
            "  Downloading azureml_dataset_runtime-1.32.0-py3-none-any.whl (3.5 kB)\n",
            "Collecting opencensus-ext-azure==1.0.8\n",
            "  Downloading opencensus_ext_azure-1.0.8-py2.py3-none-any.whl (35 kB)\n",
            "Collecting werkzeug<=1.0.1,>=0.16.1\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Collecting applicationinsights>=0.11.7\n",
            "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
            "Collecting configparser==3.7.4\n",
            "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting json-logging-py==0.2\n",
            "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
            "Collecting dill>=0.2.7.1\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Collecting liac-arff>=2.1.1\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting itsdangerous>=0.24\n",
            "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
            "Collecting Jinja2>=2.10\n",
            "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
            "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib/python3.6/site-packages (from gunicorn->mlflow->-r /azureml-environment-setup/condaenv.v16v0cj1.requirements.txt (line 2)) (52.0.0.post20210125)\n",
            "Collecting opencensus<1.0.0,>=0.7.13\n",
            "  Downloading opencensus-0.7.13-py2.py3-none-any.whl (127 kB)\n",
            "Collecting psutil>=5.6.3\n",
            "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
            "Collecting azureml-dataprep<2.19.0a,>=2.18.0a\n",
            "  Downloading azureml_dataprep-2.18.0-py3-none-any.whl (39.4 MB)\n",
            "Collecting pyarrow<4.0.0,>=0.17.0\n",
            "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.21-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
            "Collecting azureml-dataprep-native<37.0.0,>=36.0.0\n",
            "  Downloading azureml_dataprep_native-36.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting azure-identity<1.5.0,>=1.2.0\n",
            "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
            "Collecting azureml-dataprep-rslex<1.17.0a,>=1.16.0dev0\n",
            "  Downloading azureml_dataprep_rslex-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (9.9 MB)\n",
            "Collecting msal-extensions~=0.2.2\n",
            "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting msal<2.0.0,>=1.3.0\n",
            "  Downloading msal-1.12.0-py2.py3-none-any.whl (66 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
            "Collecting portalocker~=1.0\n",
            "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-api-core<2.0.0,>=1.0.0\n",
            "  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
            "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
            "Collecting google-auth<2.0dev,>=1.25.0\n",
            "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyparsing>=2.0.2\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting immutables>=0.9\n",
            "  Downloading immutables-0.15-cp36-cp36m-manylinux1_x86_64.whl (100 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
            "Collecting prometheus_client\n",
            "  Downloading prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)\n",
            "Building wheels for collected packages: pyspark, alembic, databricks-cli, json-logging-py, fusepy, liac-arff, contextvars, prometheus-flask-exporter\n",
            "  Building wheel for pyspark (setup.py): started\n",
            "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=b6a7907133918fdd96fe0771c26fd5a47b198b4a18b38d2fd6345070c14140a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/2d/64/5c1411de860c9cbb22b41fc9d342f70c42e8e2cd69cf9259cd\n",
            "  Building wheel for alembic (setup.py): started\n",
            "  Building wheel for alembic (setup.py): finished with status 'done'\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=1fa3d60a1a22a30b6ba546004c963b420c083c68f807abca17875d2a3ef44bfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
            "  Building wheel for databricks-cli (setup.py): started\n",
            "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100555 sha256=f556b032914cd528379a9126a788f2b9b5f9f4e120c5e47eb554d872737a9448\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/88/95/bd32d0e2dc0cf30e55574faab3118df2bb9ebebc60978c147b\n",
            "  Building wheel for json-logging-py (setup.py): started\n",
            "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
            "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=d95f785b81feb0bf51a52e018fedf701b862dca45e3bfc06cdb4e489cefa6dab\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10502 sha256=5ba91f6bebf6d3c6c462b58c7d4c4a2a06c49b6529a3ac0fcae5063317ed96ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "  Building wheel for liac-arff (setup.py): started\n",
            "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=bcd2b8869e114a5a61a5ea8b4cf7b768d6e18703e1f3d8196a701e87565d5dd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
            "  Building wheel for contextvars (setup.py): started\n",
            "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=642f77a5c8b8818fa1ea983f818891891d0f817db952c3018611534ed03326c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
            "  Building wheel for prometheus-flask-exporter (setup.py): started\n",
            "  Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17399 sha256=415d90f85ebd32b349b14834df37292396865feb0240cbf52deb6c251b5295b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/77/e8/3ca90b66243b0b58d5a5323a3da02cc8c5daf1de7a65141701\n",
            "Successfully built pyspark alembic databricks-cli json-logging-py fusepy liac-arff contextvars prometheus-flask-exporter\n",
            "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, chardet, requests, pyasn1, portalocker, oauthlib, msal, zipp, typing-extensions, rsa, requests-oauthlib, pyparsing, pyasn1-modules, protobuf, msal-extensions, isodate, immutables, distro, cachetools, azure-core, smmap, packaging, msrest, MarkupSafe, importlib-metadata, googleapis-common-protos, google-auth, dotnetcore2, contextvars, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, werkzeug, websocket-client, tabulate, ruamel.yaml.clib, pyopenssl, pyarrow, opencensus-context, msrestazure, Jinja2, jeepney, itsdangerous, greenlet, google-api-core, gitdb, click, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, sqlalchemy, SecretStorage, ruamel.yaml, pyyaml, python-editor, psutil, prometheus-client, pathspec, opencensus, ndg-httpsclient, Mako, liac-arff, jsonpickle, jmespath, gitpython, fusepy, Flask, entrypoints, docker, dill, databricks-cli, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, sqlparse, querystring-parser, py4j, prometheus-flask-exporter, opencensus-ext-azure, mlflow-skinny, json-logging-py, gunicorn, configparser, azureml-model-management-sdk, azureml-core, applicationinsights, alembic, pyspark, mlflow, azureml-mlflow, azureml-defaults\n",
            "Successfully installed Flask-1.0.3 Jinja2-3.0.1 Mako-1.1.4 MarkupSafe-2.0.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 alembic-1.4.1 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.16.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.0.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.0.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.32.0 azureml-dataprep-2.18.0 azureml-dataprep-native-36.0.0 azureml-dataprep-rslex-1.16.1 azureml-dataset-runtime-1.32.0 azureml-defaults-1.32.0 azureml-mlflow-1.32.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cachetools-4.2.2 cffi-1.14.6 chardet-4.0.0 click-8.0.1 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 contextvars-2.4 cryptography-3.4.7 databricks-cli-0.14.3 dill-0.3.4 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.21 entrypoints-0.3 fusepy-3.0.1 gitdb-4.0.7 gitpython-3.1.18 google-api-core-1.31.0 google-auth-1.32.1 googleapis-common-protos-1.53.0 greenlet-1.1.0 gunicorn-20.1.0 idna-2.10 immutables-0.15 importlib-metadata-4.6.1 isodate-0.6.0 itsdangerous-2.0.1 jeepney-0.7.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 mlflow-1.18.0 mlflow-skinny-1.18.0 msal-1.12.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.1 opencensus-0.7.13 opencensus-context-0.1.2 opencensus-ext-azure-1.0.8 packaging-21.0 pathspec-0.8.1 portalocker-1.7.1 prometheus-client-0.11.0 prometheus-flask-exporter-0.18.2 protobuf-3.17.3 psutil-5.8.0 py4j-0.10.9 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pyopenssl-20.0.1 pyparsing-2.4.7 pyspark-3.1.2 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.6 smmap-4.0.0 sqlalchemy-1.4.20 sqlparse-0.4.1 tabulate-0.8.9 typing-extensions-3.10.0.0 urllib3-1.26.5 websocket-client-1.1.0 werkzeug-1.0.1 zipp-3.5.0\n",
            "\u001b[91m\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.10.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "WARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container 5a39e315471c\n",
            " ---> 2d41fec30ec4\n",
            "Step 9/18 : ENV PATH /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/bin:$PATH\n",
            " ---> Running in af91df4b7b25\n",
            "Removing intermediate container af91df4b7b25\n",
            " ---> 319f1356677a\n",
            "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> 961e2952f038\n",
            "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> 9e13769a204a\n",
            "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353\n",
            " ---> Running in 22dfccfe3020\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container 22dfccfe3020\n",
            " ---> cc3c4a1929d2\n",
            "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353\n",
            " ---> Running in 61bf1c4c9d5d\n",
            "Removing intermediate container 61bf1c4c9d5d\n",
            " ---> e5ba861c348e\n",
            "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_f2739031ae37a487a0872ec6d8eff353/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in c48c87e8e48d\n",
            "Removing intermediate container c48c87e8e48d\n",
            " ---> 3a52d8d37f47\n",
            "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> 8b7fb816e648\n",
            "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
            " ---> Running in cad3de7b43a4\n",
            "Removing intermediate container cad3de7b43a4\n",
            " ---> 25136fbe759a\n",
            "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in bfb1cf1333e2\n",
            "Removing intermediate container bfb1cf1333e2\n",
            " ---> 2e7cd66f0fcd\n",
            "Step 18/18 : CMD [\"bash\"]\n",
            " ---> Running in 03443f3d6cf3\n",
            "Removing intermediate container 03443f3d6cf3\n",
            " ---> a31071ed73c8\n",
            "Successfully built a31071ed73c8\n",
            "Successfully tagged rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:latest\n",
            "Successfully tagged rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:1\n",
            "2021/07/11 05:45:34 Successfully executed container: acb_step_0\n",
            "2021/07/11 05:45:34 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/07/11 05:45:34 Pushing image: rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:1, attempt 1\n",
            "The push refers to repository [rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb]\n",
            "60448cf56ca5: Preparing\n",
            "fe81a7a3ae3f: Preparing\n",
            "3e5b25c250b9: Preparing\n",
            "cecf7889e8ed: Preparing\n",
            "56f3030a3ba8: Preparing\n",
            "ca9d31d93ff4: Preparing\n",
            "2701e2d60f3a: Preparing\n",
            "e6a127c6eae0: Preparing\n",
            "cad9b1b491aa: Preparing\n",
            "fe09032048fd: Preparing\n",
            "cbe733e9771d: Preparing\n",
            "74218ef6464a: Preparing\n",
            "5ba1f0778181: Preparing\n",
            "658e73e9fcdf: Preparing\n",
            "b48835f37b9c: Preparing\n",
            "a7c59d42f9e5: Preparing\n",
            "bb7a0d4412a3: Preparing\n",
            "5f08512fd434: Preparing\n",
            "c7bb31fc0e08: Preparing\n",
            "50858308da3d: Preparing\n",
            "ca9d31d93ff4: Waiting\n",
            "2701e2d60f3a: Waiting\n",
            "e6a127c6eae0: Waiting\n",
            "cad9b1b491aa: Waiting\n",
            "fe09032048fd: Waiting\n",
            "cbe733e9771d: Waiting\n",
            "74218ef6464a: Waiting\n",
            "5ba1f0778181: Waiting\n",
            "658e73e9fcdf: Waiting\n",
            "b48835f37b9c: Waiting\n",
            "a7c59d42f9e5: Waiting\n",
            "bb7a0d4412a3: Waiting\n",
            "5f08512fd434: Waiting\n",
            "c7bb31fc0e08: Waiting\n",
            "50858308da3d: Waiting\n",
            "cecf7889e8ed: Pushed\n",
            "60448cf56ca5: Pushed\n",
            "3e5b25c250b9: Pushed\n",
            "fe81a7a3ae3f: Pushed\n",
            "ca9d31d93ff4: Pushed\n",
            "2701e2d60f3a: Pushed\n",
            "e6a127c6eae0: Pushed\n",
            "cad9b1b491aa: Pushed\n",
            "fe09032048fd: Pushed\n",
            "cbe733e9771d: Pushed\n",
            "74218ef6464a: Pushed\n",
            "5ba1f0778181: Pushed\n",
            "658e73e9fcdf: Pushed\n",
            "a7c59d42f9e5: Pushed\n",
            "b48835f37b9c: Pushed\n",
            "5f08512fd434: Pushed\n",
            "c7bb31fc0e08: Pushed\n",
            "\n",
            "bb7a0d4412a3: Pushed\n",
            "50858308da3d: Pushed\n",
            "\n",
            "56f3030a3ba8: Pushed\n",
            "1: digest: sha256:4c9ef1e4c73b3f7525dc58a6ac8a1a7556855e5d7085f3a486946959c42dabab size: 4514\n",
            "2021/07/11 05:48:19 Successfully pushed image: rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:1\n",
            "2021/07/11 05:48:19 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2021/07/11 05:48:19 Pushing image: rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:latest, attempt 1\n",
            "The push refers to repository [rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb]\n",
            "60448cf56ca5: Preparing\n",
            "fe81a7a3ae3f: Preparing\n",
            "3e5b25c250b9: Preparing\n",
            "cecf7889e8ed: Preparing\n",
            "56f3030a3ba8: Preparing\n",
            "ca9d31d93ff4: Preparing\n",
            "2701e2d60f3a: Preparing\n",
            "e6a127c6eae0: Preparing\n",
            "cad9b1b491aa: Preparing\n",
            "fe09032048fd: Preparing\n",
            "cbe733e9771d: Preparing\n",
            "74218ef6464a: Preparing\n",
            "5ba1f0778181: Preparing\n",
            "658e73e9fcdf: Preparing\n",
            "b48835f37b9c: Preparing\n",
            "a7c59d42f9e5: Preparing\n",
            "bb7a0d4412a3: Preparing\n",
            "5f08512fd434: Preparing\n",
            "c7bb31fc0e08: Preparing\n",
            "50858308da3d: Preparing\n",
            "ca9d31d93ff4: Waiting\n",
            "2701e2d60f3a: Waiting\n",
            "e6a127c6eae0: Waiting\n",
            "cad9b1b491aa: Waiting\n",
            "fe09032048fd: Waiting\n",
            "cbe733e9771d: Waiting\n",
            "74218ef6464a: Waiting\n",
            "658e73e9fcdf: Waiting\n",
            "b48835f37b9c: Waiting\n",
            "a7c59d42f9e5: Waiting\n",
            "bb7a0d4412a3: Waiting\n",
            "5f08512fd434: Waiting\n",
            "c7bb31fc0e08: Waiting\n",
            "50858308da3d: Waiting\n",
            "5ba1f0778181: Waiting\n",
            "cecf7889e8ed: Layer already exists\n",
            "fe81a7a3ae3f: Layer already exists\n",
            "60448cf56ca5: Layer already exists\n",
            "3e5b25c250b9: Layer already exists\n",
            "56f3030a3ba8: Layer already exists\n",
            "e6a127c6eae0: Layer already exists\n",
            "2701e2d60f3a: Layer already exists\n",
            "fe09032048fd: Layer already exists\n",
            "ca9d31d93ff4: Layer already exists\n",
            "cad9b1b491aa: Layer already exists\n",
            "74218ef6464a: Layer already exists\n",
            "cbe733e9771d: Layer already exists\n",
            "658e73e9fcdf: Layer already exists\n",
            "b48835f37b9c: Layer already exists\n",
            "5ba1f0778181: Layer already exists\n",
            "a7c59d42f9e5: Layer already exists\n",
            "bb7a0d4412a3: Layer already exists\n",
            "c7bb31fc0e08: Layer already exists\n",
            "5f08512fd434: Layer already exists\n",
            "50858308da3d: Layer already exists\n",
            "latest: digest: sha256:4c9ef1e4c73b3f7525dc58a6ac8a1a7556855e5d7085f3a486946959c42dabab size: 4514\n",
            "2021/07/11 05:48:21 Successfully pushed image: rohancr.azurecr.io/azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb:latest\n",
            "2021/07/11 05:48:21 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 262.543912)\n",
            "2021/07/11 05:48:21 Populating digests for step ID: acb_step_0...\n",
            "2021/07/11 05:48:24 Successfully populated digests for step ID: acb_step_0\n",
            "2021/07/11 05:48:24 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 165.369887)\n",
            "2021/07/11 05:48:24 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.428693)\n",
            "2021/07/11 05:48:24 The following dependencies were found:\n",
            "2021/07/11 05:48:24 \n",
            "- image:\n",
            "    registry: rohancr.azurecr.io\n",
            "    repository: azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb\n",
            "    tag: latest\n",
            "    digest: sha256:4c9ef1e4c73b3f7525dc58a6ac8a1a7556855e5d7085f3a486946959c42dabab\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
            "    tag: 20210615.v1\n",
            "    digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: rohancr.azurecr.io\n",
            "    repository: azureml/azureml_f46cbbea7b874ce4db996ddce87a1deb\n",
            "    tag: \"1\"\n",
            "    digest: sha256:4c9ef1e4c73b3f7525dc58a6ac8a1a7556855e5d7085f3a486946959c42dabab\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
            "    tag: 20210615.v1\n",
            "    digest: sha256:8360f8650a20d3a4932c9ba4e476b2481445c224e16905a68fc6edb718d85e28\n",
            "  git: {}\n",
            "\n",
            "\n",
            "Run ID: cuc was successful after 7m19s\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_2e32966ad56d2e776603963d18dd6f6a8d7a59b0a81aa04633a4e1bb0d13631a_d.txt\n",
            "========================================================================================================================\n",
            "2021-07-11T05:51:57Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24790 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            "2021-07-11T05:51:58Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/mounts/workspaceblobstore\n",
            "2021-07-11T05:51:58Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
            "2021-07-11T05:51:58Z Starting output-watcher...\n",
            "2021-07-11T05:51:58Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
            "92473f7ef455: Pulling fs layer\n",
            "fb52bde70123: Pulling fs layer\n",
            "64788f86be3f: Pulling fs layer\n",
            "33f6d5f2e001: Pulling fs layer\n",
            "eeb715f1b6ae: Pulling fs layer\n",
            "fe519cf36537: Pulling fs layer\n",
            "58ff99196c15: Pulling fs layer\n",
            "9b13f06a8eff: Pulling fs layer\n",
            "2d4e93adbf58: Pulling fs layer\n",
            "6ee7c3767844: Pulling fs layer\n",
            "62cfc3ccb8ab: Pulling fs layer\n",
            "4a7af9d757ee: Pulling fs layer\n",
            "9e11d437728f: Pulling fs layer\n",
            "3506c910620f: Pulling fs layer\n",
            "afe6352c52c2: Pulling fs layer\n",
            "45d886309004: Pulling fs layer\n",
            "2ce19e789040: Pulling fs layer\n",
            "f2a2950e1ed4: Pulling fs layer\n",
            "33f6d5f2e001: Waiting\n",
            "eeb715f1b6ae: Waiting\n",
            "62cfc3ccb8ab: Waiting\n",
            "4a7af9d757ee: Waiting\n",
            "fe519cf36537: Waiting\n",
            "58ff99196c15: Waiting\n",
            "9b13f06a8eff: Waiting\n",
            "9e11d437728f: Waiting\n",
            "2d4e93adbf58: Waiting\n",
            "6ee7c3767844: Waiting\n",
            "3506c910620f: Waiting\n",
            "afe6352c52c2: Waiting\n",
            "f2a2950e1ed4: Waiting\n",
            "45d886309004: Waiting\n",
            "2ce19e789040: Waiting\n",
            "fb52bde70123: Verifying Checksum\n",
            "fb52bde70123: Download complete\n",
            "64788f86be3f: Verifying Checksum\n",
            "64788f86be3f: Download complete\n",
            "33f6d5f2e001: Verifying Checksum\n",
            "33f6d5f2e001: Download complete\n",
            "92473f7ef455: Verifying Checksum\n",
            "92473f7ef455: Download complete\n",
            "fe519cf36537: Verifying Checksum\n",
            "fe519cf36537: Download complete\n",
            "58ff99196c15: Verifying Checksum\n",
            "58ff99196c15: Download complete\n",
            "9b13f06a8eff: Verifying Checksum\n",
            "9b13f06a8eff: Download complete\n",
            "eeb715f1b6ae: Verifying Checksum\n",
            "eeb715f1b6ae: Download complete\n",
            "62cfc3ccb8ab: Verifying Checksum\n",
            "62cfc3ccb8ab: Download complete\n",
            "4a7af9d757ee: Verifying Checksum\n",
            "4a7af9d757ee: Download complete\n",
            "6ee7c3767844: Verifying Checksum\n",
            "6ee7c3767844: Download complete\n",
            "9e11d437728f: Download complete\n",
            "afe6352c52c2: Verifying Checksum\n",
            "afe6352c52c2: Download complete\n",
            "45d886309004: Verifying Checksum\n",
            "45d886309004: Download complete\n",
            "2d4e93adbf58: Verifying Checksum\n",
            "2d4e93adbf58: Download complete\n",
            "2ce19e789040: Verifying Checksum\n",
            "2ce19e789040: Download complete\n",
            "f2a2950e1ed4: Verifying Checksum\n",
            "f2a2950e1ed4: Download complete\n",
            "92473f7ef455: Pull complete\n",
            "fb52bde70123: Pull complete\n",
            "64788f86be3f: Pull complete\n",
            "33f6d5f2e001: Pull complete\n",
            "3506c910620f: Verifying Checksum\n",
            "3506c910620f: Download complete\n",
            "eeb715f1b6ae: Pull complete\n",
            "fe519cf36537: Pull complete\n",
            "58ff99196c15: Pull complete\n",
            "9b13f06a8eff: Pull complete\n",
            "2d4e93adbf58: Pull complete\n",
            "6ee7c3767844: Pull complete\n",
            "62cfc3ccb8ab: Pull complete\n",
            "4a7af9d757ee: Pull complete\n",
            "9e11d437728f: Pull complete\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_af0020a59c90f864c84e751ce4adde030415c6ccb6c17942a2066c7e09bbff99_d.txt\n",
            "===============================================================================================================\n",
            "[2021-07-11T05:52:24.378609] Entering job preparation.\n",
            "[2021-07-11T05:52:25.051544] Starting job preparation.\n",
            "[2021-07-11T05:52:25.051572] Extracting the control code.\n",
            "[2021-07-11T05:52:25.051991] Starting extract_project.\n",
            "[2021-07-11T05:52:25.052170] Starting to extract zip file.\n",
            "[2021-07-11T05:52:25.083153] Finished extracting zip file.\n",
            "[2021-07-11T05:52:25.085759] Using urllib.request Python 3.0 or later\n",
            "[2021-07-11T05:52:25.085866] Start fetching snapshots.\n",
            "[2021-07-11T05:52:25.085970] Start fetching snapshot.\n",
            "[2021-07-11T05:52:25.086049] Retrieving project from snapshot: 11ec9ce1-7481-4fbf-b2fd-52b19a17ec40\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 40\n",
            "[2021-07-11T05:52:25.503165] Finished fetching snapshot.\n",
            "[2021-07-11T05:52:25.503197] Start fetching snapshot.\n",
            "[2021-07-11T05:52:25.503293] Retrieving project from snapshot: d0c57f8d-9f67-42a2-8634-16a49782dd43\n",
            "\n",
            "Streaming azureml-logs/65_job_prep-tvmps_2e32966ad56d2e776603963d18dd6f6a8d7a59b0a81aa04633a4e1bb0d13631a_d.txt\n",
            "===============================================================================================================\n",
            "[2021-07-11T05:52:24.998899] Entering job preparation.\n",
            "[2021-07-11T05:52:25.672717] Starting job preparation.\n",
            "[2021-07-11T05:52:25.672751] Extracting the control code.\n",
            "[2021-07-11T05:52:25.673012] Starting extract_project.\n",
            "[2021-07-11T05:52:25.673055] Starting to extract zip file.\n",
            "[2021-07-11T05:52:25.691233] Finished extracting zip file.\n",
            "[2021-07-11T05:52:25.693278] Using urllib.request Python 3.0 or later\n",
            "[2021-07-11T05:52:25.693366] Start fetching snapshots.\n",
            "[2021-07-11T05:52:25.693422] Start fetching snapshot.\n",
            "[2021-07-11T05:52:25.693435] Retrieving project from snapshot: 11ec9ce1-7481-4fbf-b2fd-52b19a17ec40\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 41\n",
            "[2021-07-11T05:52:26.052078] Finished fetching snapshot.\n",
            "[2021-07-11T05:52:26.052106] Start fetching snapshot.\n",
            "[2021-07-11T05:52:26.052199] Retrieving project from snapshot: d0c57f8d-9f67-42a2-8634-16a49782dd43\n",
            "[2021-07-11T05:52:34.177842] Finished fetching snapshot.\n",
            "[2021-07-11T05:52:34.177872] Finished fetching snapshots.\n",
            "[2021-07-11T05:52:34.177960] Finished extract_project.\n",
            "[2021-07-11T05:52:34.178014] Finished fetching and extracting the control code.\n",
            "[2021-07-11T05:52:34.184059] Start run_history_prep.\n",
            "[2021-07-11T05:52:34.190058] Job preparation is complete.\n",
            "[2021-07-11T05:52:34.190288] Entering Data Context Managers in Sidecar\n",
            "[2021-07-11T05:52:34.191039] Running Sidecar prep cmd...\n",
            "[2021-07-11T05:52:34.488460] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626\n",
            "[2021-07-11T05:52:34.489136] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
            "Enter __enter__ of DatasetContextManager\n",
            "SDK version: azureml-core==1.28.0 azureml-dataprep==2.16.0. Session id: 85326f4c-4b5c-4968-8772-81bf07ed65ed. Run id: c3e422d5-b7d0-4eca-b33d-73a0a752d626.\n",
            "Processing 'leads_batch'.\n",
            "Processing dataset FileDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"('rohands', 'batch-data/')\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetDatastoreFiles\"\n",
            "  ],\n",
            "  \"registration\": {\n",
            "    \"id\": \"c73804df-9317-415e-b2ed-32de72b2948b\",\n",
            "    \"name\": \"leads-batch-data\",\n",
            "    \"version\": 1,\n",
            "    \"description\": \"batch data for Marketing Leads UCI\",\n",
            "    \"workspace\": \"Workspace.create(name='rohan-ws', subscription_id='23416925-66df-470c-b651-f378856d8ad7', resource_group='rohan-rg')\"\n",
            "  }\n",
            "}\n",
            "Mounting leads_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/leads_batch_c73804df-9317-415e-b2ed-32de72b2948b.\n",
            "Mounted leads_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/leads_batch_c73804df-9317-415e-b2ed-32de72b2948b as folder.\n",
            "Processing 'inferences'.\n",
            "Already registered authentication for run id: c3e422d5-b7d0-4eca-b33d-73a0a752d626\n",
            "Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/inferences_workspaceblobstore.\n",
            "Exit __enter__ of DatasetContextManager\n",
            "Set Dataset leads_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/leads_batch_c73804df-9317-415e-b2ed-32de72b2948b\n",
            "Set OutputDataset inferences's target path to /tmp/f892b7aa-cc2a-46c8-9ec2-049266fa9f29\n",
            "[2021-07-11T05:52:48.371549] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
            "[2021-07-11T05:52:48.972141] Ran Sidecar prep cmd.\n",
            "[2021-07-11T05:52:48.972213] Running Context Managers in Sidecar complete.\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/07/11 05:53:35 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/07/11 05:53:35 Version: 3.0.01632.0003 Branch: .SourceBranch Commit: 4b96fb0\n",
            "2021/07/11 05:53:35 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\n",
            "2021/07/11 05:53:35 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
            "[2021-07-11T05:53:35.605818] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'leads_batch'])\n",
            "Script type = None\n",
            "[2021-07-11T05:53:36.023552] Entering Run History Context Manager.\n",
            "[2021-07-11T05:53:38.969983] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626\n",
            "[2021-07-11T05:53:38.970234] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'leads_batch']\n",
            "[2021-07-11T05:53:38.970260] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.32.0', '--scoring_module_name', 'score.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/tmp/f892b7aa-cc2a-46c8-9ec2-049266fa9f29', '--input_fds_0', 'leads_batch']\n",
            "\n",
            "2021/07/11 05:53:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "\n",
            "\n",
            "[2021-07-11T05:56:08.552883] The experiment failed. Finalizing run...\n",
            "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
            "3 items cleaning up...\n",
            "Cleanup took 0.1541750431060791 seconds\n",
            "azureml_common.parallel_run.exception_info.Exception: Run failed. Below is the error detail:\n",
            "EntryScriptException: Entry script error. All tries to load the entry script or calling init() failed. Please check logs/user/error/* and logs/sys/error/* to see if some errors have occurred.\n",
            "No mini batch has been completed. Consider a succeeded mini batch or failed mini batch reached the max tries as completed.\n",
            "The init() function in the entry script had raised exception for 13 times. Please check logs at logs/user/error/* for details.\n",
            "  * Error 'module '__main__' has no attribute 'ColumnRenamer'' occurred 26 times.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"driver/amlbi_main.py\", line 167, in <module>\n",
            "    main()\n",
            "  File \"driver/amlbi_main.py\", line 123, in main\n",
            "    boot(driver_dir)\n",
            "  File \"driver/amlbi_main.py\", line 58, in boot\n",
            "    booter.start()\n",
            "  File \"driver/azureml_user/parallel_run/boot.py\", line 361, in start\n",
            "    self.start_sys_main()\n",
            "  File \"driver/azureml_user/parallel_run/boot.py\", line 259, in start_sys_main\n",
            "    self.run_sys_main(cmd)\n",
            "  File \"driver/azureml_user/parallel_run/boot_simulator.py\", line 40, in run_sys_main\n",
            "    self.run(cmd)\n",
            "  File \"driver/azureml_user/parallel_run/boot.py\", line 201, in run\n",
            "    self.check_run_result(proc=proc, stdout=stdout, stderr=stderr)\n",
            "  File \"driver/azureml_user/parallel_run/boot.py\", line 211, in check_run_result\n",
            "    BootResult().check_result(stdout)\n",
            "  File \"driver/azureml_user/parallel_run/boot_result.py\", line 36, in check_result\n",
            "    raise Exception(message) from cause\n",
            "Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n",
            "\n",
            "[2021-07-11T05:56:08.888372] Finished context manager injector with Exception.\n",
            "2021/07/11 05:56:09 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: /mnt/batch/tasks/workitems/7dfda1c4-c525-4bf0-9175-37a9199dc9a8/job-1/c3e422d5-b7d0-4eca-b_e1ec1ce9-84d2-40bb-9c37-205b06e960a8/wd/runTaskLetTask_error.json\n",
            "2021/07/11 05:56:09 Wrapper cmd failed with err: exit status 1\n",
            "2021/07/11 05:56:09 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
            "2021/07/11 05:56:09 mpirun version string: {\n",
            "mpirun (Open MPI) 3.1.2\n",
            "\n",
            "Report bugs to http://www.open-mpi.org/community/help/\n",
            "}\n",
            "2021/07/11 05:56:09 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 2\n",
            "FilteredData: 0.\n",
            "2021/07/11 05:56:09 Process Exiting with Code:  1\n",
            "2021/07/11 05:56:10 All App Insights Logs was sent successfully or the close timeout of 20 was reached\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_2e32966ad56d2e776603963d18dd6f6a8d7a59b0a81aa04633a4e1bb0d13631a_d.txt\n",
            "===============================================================================================================\n",
            "[2021-07-11T05:56:13.007087] Entering job release\n",
            "[2021-07-11T05:56:13.697343] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-07-11T05:56:13.697378] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-07-11T05:56:13.697545] Running in AzureML-Sidecar, starting to exit user context managers...\n",
            "[2021-07-11T05:56:13.698030] Running Sidecar release cmd...\n",
            "[2021-07-11T05:56:13.769454] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626\n",
            "Enter __exit__ of DatasetContextManager\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/leads_batch_c73804df-9317-415e-b2ed-32de72b2948b.\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/leads_batch_c73804df-9317-415e-b2ed-32de72b2948b.\n",
            "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/inferences_workspaceblobstore.\n",
            "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/inferences_workspaceblobstore: Invalid argument\n",
            "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/rohan-ws/azureml/c3e422d5-b7d0-4eca-b33d-73a0a752d626/wd/inferences_workspaceblobstore.\n",
            "Exit __exit__ of DatasetContextManager\n",
            "[2021-07-11T05:56:13.807872] Removing absolute paths from host...\n",
            "[2021-07-11T05:56:13.808090] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
            "[2021-07-11T05:56:14.623006] Ran Sidecar release cmd.\n",
            "\n",
            "StepRun(batch-score-leads) Execution Summary\n",
            "=============================================\n",
            "StepRun( batch-score-leads ) Status: Failed\n",
            "\n",
            "Warnings:\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": \"UserError\",\n",
            "    \"severity\": null,\n",
            "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
            "    \"messageFormat\": \"{Message}\",\n",
            "    \"messageParameters\": {\n",
            "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
            "    },\n",
            "    \"referenceCode\": null,\n",
            "    \"detailsUri\": null,\n",
            "    \"target\": null,\n",
            "    \"details\": [],\n",
            "    \"innerError\": {\n",
            "      \"code\": \"UserTrainingScriptFailed\",\n",
            "      \"innerError\": null\n",
            "    },\n",
            "    \"debugInfo\": null,\n",
            "    \"additionalInfo\": null\n",
            "  },\n",
            "  \"correlation\": {\n",
            "    \"operation\": \"ba77786236190b479265cff2d7689c88\",\n",
            "    \"request\": \"a46dcb8a368e663b\"\n",
            "  },\n",
            "  \"environment\": \"centralindia\",\n",
            "  \"location\": \"centralindia\",\n",
            "  \"time\": \"2021-07-11T05:56:27.7211309+00:00\",\n",
            "  \"componentName\": \"execution-worker\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a30e2517756a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparallelrun_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'leads-batch-pipeline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 295\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    296\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 737\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(name='leads-batch-pipeline', description='Batch scoring of leads data from UCI', version='1.0')\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "from azureml.pipeline.core.run import PipelineRun\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "import requests\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, headers=auth_header, json={\"ExperimentName\": \"leads-batch-pipeline\"})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "\r\n",
        "published_pipeline_run = PipelineRun(ws.experiments['leads-batch-pipeline'], run_id)\r\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\r\n",
        ".addGrid(gbt.maxDepth,[5,10])\r\n",
        ".addGrid(gbt.maxIter,[10,50])\r\n",
        ".addGrid(gbt.maxBins,[16,32])\r\n",
        ".addGrid(gbt.stepSize,[0.05,0.1])\r\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625970416665
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}